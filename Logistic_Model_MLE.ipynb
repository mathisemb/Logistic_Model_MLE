{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29e618c5",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92d3091",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dc1f11",
   "metadata": {},
   "source": [
    "## <font color=darkblue>Implémentation du maximum de vraisemblance pour le modèle de régression logistique</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6f705c",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae932025",
   "metadata": {},
   "source": [
    "L'objectif de la régression logistique est d'expliquer une variable binaire par des observations réelles indépendantes. Pour y parvenir on estime le paramètre inconnu qui lie les observations et la variable binaire. On se place donc dans un cadre paramétrique. Commençons par détailler le modèle de régression logistique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b36bcf",
   "metadata": {},
   "source": [
    "# <font color=darkgreen>1. Le modèle</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baaff38",
   "metadata": {},
   "source": [
    "La régression logistique appartient à une classe de modèles dits de classification supervisée. Donnons en une définition formelle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03480928",
   "metadata": {},
   "source": [
    "**Définition** Le `modèle de classification supervisée` correspond à la donnée de $\\mathcal{D}_n = (X_i,Y_i)_{1\\leq i\\leq n}$ les observations où $(X_i,Y_i) \\stackrel{iid}{\\sim} (X,Y)$ un couple générique de loi $P_{X,Y}$ où $X \\in \\mathbb{R}^d$, est la variable dite explicative (de dimension $d \\in \\mathbb{N}$) et $Y \\in \\{ 0,1 \\}$ la variable expliquée."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efae4646",
   "metadata": {},
   "source": [
    "Naturellement, après avoir observé des données ET leurs étiquettes, on aimerait pouvoir faire des prédictions. Sur quelle quantité concentrer nos efforts ? C'est ce qu'on peut espérer sachant la donnée."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f271c2",
   "metadata": {},
   "source": [
    "**Définition** On appelle fonction de régression la fonction\n",
    "$$\n",
    "    \\eta : x \\in \\mathbb{R}^d \\mapsto \\eta(x) = \\mathbb{E}[Y|X=x] = P(Y=1|X=x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020d5b98",
   "metadata": {},
   "source": [
    "Puisque la loi du couple générique $(X,Y)$ est inconnue, nous ferons comme d'habitude en statistique : un estimateur."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a0d4b4",
   "metadata": {},
   "source": [
    "Précisons maintenant le cadre de la régression logistique qui consiste simplement en l'ajout d'une hypothèse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a6283f",
   "metadata": {},
   "source": [
    "**Définition** Le `modèle de régression logistique` correspond à un modèle de classification supervisée sur lequel on fait l'`hypothèse logistique` : $\\exists \\beta \\in \\mathbb{R}^d, \\exists a \\in \\mathbb{R}, \\forall x \\in \\mathbb{R}^d$,\n",
    "$$\n",
    "    log\\left( \\frac{\\eta(x)}{1-\\eta(x)} \\right) = \\beta^Tx+a\n",
    "$$\n",
    "\n",
    "**Il est important de remarquer que** $1 - \\eta(x) = P(Y=0|X=x)$ donc\n",
    "$ P(Y=1|X=x) \\geq P(Y=0|X=x) \\iff log\\left( \\frac{\\eta(x)}{1-\\eta(x)} \\right) \\geq 0 $.\\\n",
    "Par conséquent, \n",
    "$$\\boxed{\\beta^Tx+a \\geq 0 \\implies \\text{Y=1 est plus probable que Y=0}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1d2031",
   "metadata": {},
   "source": [
    "Il nous suffit donc d'estimer les deux paramètres $\\beta$ et $a$. Exprimons donc la vraisemblance du modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e36368",
   "metadata": {},
   "source": [
    "Puisque $\\eta(x) = \\frac{exp(\\beta^Tx+a)}{1+exp\\beta^Tx+a)}$, on a $\\mathcal{L}((Y_i)_{1\\leq i\\leq n} | (X_i)_{1\\leq i\\leq n}) = \\bigotimes_{i=1}^n \\mathcal{B}(\\eta(X_i)) = \\bigotimes_{i=1}^n \\mathcal{B}\\left(\\frac{exp(\\beta^TX_i+a)}{1+exp(\\beta^TX_i+a)}\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500aa888",
   "metadata": {},
   "source": [
    ">**Rappel** : si les $(X_i)_{1\\leq i\\leq n}$ sont indépendants à valeurs dans $(X,\\mathcal{X})$ muni d'une mesure de référence $\\mu$, et que la loi de $X_1$ a une densité $p_{\\theta_0}$ par rapport à $\\mu$ où $p_{\\theta_0} \\in \\left\\{ p_{\\theta}, \\theta \\in \\Theta \\right\\}$, par indépendance des $X_i$, la fonction de `vraisemblance` s'écrit alors\n",
    "$$L_n : \\theta \\mapsto p_{\\theta}(X_1,...,X_n) = \\prod_{i=1}^{n}p_{\\theta}(X_i)\n",
    "$$\n",
    "Et la `log-vraisemblance`\n",
    "$$\n",
    "l_n : \\theta \\mapsto log(p_{\\theta}(X_1,...,X_n)) = \\sum_{i=1}^{n}log(p_{\\theta}(X_i))\n",
    "$$\n",
    "On appelle `maximum de vraisemlance` tout $\\hat{\\theta}_n^{MV}$ tel que\n",
    "$$\n",
    "    \\hat{\\theta}_n^{MV} \\in \\underset{\\theta \\in \\Theta}{\\mathrm{argmin}}\\:l_n(\\theta)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e9bfd5",
   "metadata": {},
   "source": [
    "Puisque la densité d'une $\\mathcal{B}(p)$ peut s'écrire comme $x \\in \\{0,1\\} \\mapsto p^x(1-p)^{1-x}$ et que les données sont indépendantes, la vraisemblance s'écrit\n",
    "$$\n",
    "    \\prod_{i=1}^n\n",
    "    \\left(     \\frac{exp(\\beta^TX_i+a)}{1+exp(\\beta^TX_i+a)} \\right)^{Y_i}\n",
    "    \\left( 1 - \\frac{exp(\\beta^TX_i+a)}{1+exp(\\beta^TX_i+a)} \\right)^{1 - Y_i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca49f5f6",
   "metadata": {},
   "source": [
    "Finalement on obtient la log-vraisemblance du modèle logistique\n",
    "<font color=darkred>\n",
    "    $$l_n(\\beta,a) = \\sum_{i=1}^n \\left( Y_i\\left(\\beta^TX_i+a\\right) - log\\left(1+e^{\\beta^TX_i+a}\\right) \\right)$$\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd99609",
   "metadata": {},
   "source": [
    "Une fois qu'on a estimé $\\beta$ et $a$ par $\\hat{\\beta}$ et $\\hat{a}$ en maximisant cette vraisemblance, on obtient l'estimateur plug-in du classifieur $h(x) = \\mathbb{1}\\left\\{ \\eta(x) \\geq \\frac{1}{2} \\right\\}$ :\n",
    "<font color=darkred>\n",
    "    $$\\hat{h}(x) = \\mathbb{1}\\left\\{ \\hat{\\beta}^Tx + \\hat{a} \\geq 0 \\right\\}$$\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b62177",
   "metadata": {},
   "source": [
    "**La question est maintenant de savoir comment maximiser cette vraisemblance**. En effet la tâche n'est pas simple car son maximum n'est pas explicitement calculable. Ainsi l'objectif de ce notebook est de voir quelles méthodes nous permettent de contourner ce problème. Nous commençerons par la célèbre méthode de gradient, puis nous passerons à une méthode du 2nd ordre : Newton-Raphson. Finalement nous expliquerons l'algorithme Expectation-Maximisation introduit en 1977 et plus tard largement utilisé en apprentissage automatique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beffc40d",
   "metadata": {},
   "source": [
    "# <font color=darkgreen>2. Maximisation de la vraisemblance</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5259160",
   "metadata": {},
   "source": [
    "## 2.1. Méthode du 1er ordre : montée de gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c73dc6a",
   "metadata": {},
   "source": [
    "Cette méthode par de l'idée intuitive que pour atteindre le maximum il faut monter, or c'est le gradient qui nous indique la route à prendre pour monter le plus. En considérant que $\\theta = (\\beta, a)$ est le paramètre recherché, on produit une suite $\\left\\{ \\hat{\\theta}^{(K)} \\right\\}_{K\\geq0}$ d'estimateurs de $\\theta$. L'algorithme est le suivant :\\\n",
    "`Initialisation :` $\\hat{\\theta}^{(0)}$ est choisi arbitrairement\\\n",
    "`Itérations :` $\\forall K \\geq 0, \\hat{\\theta}^{(K+1)} = \\hat{\\theta}^{(K)} + \\eta_{K+1}\\nabla_{\\theta}l_n\\left(\\hat{\\theta}^{(K)}\\right)$\\\n",
    "où les $\\left(\\eta_K\\right)_{K\\geq1}$ sont des pas dans $\\mathbb{R}_+^*$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273c5998",
   "metadata": {},
   "source": [
    "Plusieurs critères d'arrêts sont possibles et peuvent être combiner. On peut par exemple citer :\n",
    "- lorsque le gradient de f est suffisamment petit : $\\| \\nabla_{\\theta}l_n\\left(\\hat{\\theta}^{(K)}\\right) \\| \\leq \\varepsilon$\n",
    "- lorsque les itérés ne progressent plus suffisamment : $\\|\\hat{\\theta}^{(K+1)} - \\hat{\\theta}^{(K)}\\| \\leq \\varepsilon$\n",
    "- lorsque les valeurs de f ne changent plus suffisamment : $\\|l_n\\left(\\hat{\\theta}^{(K+1)}\\right) - l_n\\left(\\hat{\\theta}^{(K)}\\right)\\| \\leq \\varepsilon$\n",
    "\n",
    "En plus de ces critères on peut ajouter une condition sur un nombre d'itérations maximum à ne pas dépasser."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd2a555",
   "metadata": {},
   "source": [
    "Voici le code Python implémentant cette méthode :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c532832",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "Required packages\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "import autograd.numpy as np\n",
    "import autograd\n",
    "import scipy.stats as stat\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "#import math\n",
    "#import pandas as pd\n",
    "#from autograd import grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d62f7fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOGISTIC REGRESSION LIKELIHOOD FUNCTION\n",
    "def loglikelihood(theta):\n",
    "    \"\"\"\n",
    "    Inputs\n",
    "    ----------\n",
    "    theta = np.array([beta_1,...,beta_d, a])\n",
    "    beta: parameter of dimension d\n",
    "    a: arameter of dimension 1\n",
    "    X,Y: data (global variable ?) of dimension n x d (1 line = 1 data)\n",
    "    \n",
    "    Outputs\n",
    "    -------\n",
    "    logl: loglikelihood (of dimension 1)\n",
    "    \"\"\"\n",
    "    d = len(theta)\n",
    "    beta = theta[:d-1]\n",
    "    a = theta[d-1]\n",
    "    S = 0\n",
    "    for i in range(N):\n",
    "        bTXia = np.inner(beta,X[i,:]) + a\n",
    "        S += Y[i]*bTXia - np.log(1 + np.exp(bTXia))\n",
    "    \"\"\"\n",
    "    # TODO : Vectorization\n",
    "    \"\"\"\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d52dd0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADIENT METHOD\n",
    "def gradient_met(f, x0, eta, eps, Nmax):\n",
    "    \"\"\"\n",
    "    Inputs\n",
    "    ----------\n",
    "    f: the function we want to maximize\n",
    "    x0: the initialization (of dimension R^d x R)\n",
    "    eta: the step\n",
    "    eps: the precision (stop criteria)\n",
    "    Nmax: the maximum number of iterations\n",
    "    \n",
    "    Outputs\n",
    "    -------\n",
    "    x: the minimum (of dimension R^d x R)\n",
    "    n: the number of iterations\n",
    "    cv: a boolean that indicates if the algorithm has converged\n",
    "    \"\"\"\n",
    "    n = 0\n",
    "    x = x0\n",
    "    grad_f = autograd.grad(f)\n",
    "    g = grad_f(x)\n",
    "    while(np.linalg.norm(g) > eps and n<Nmax):\n",
    "        x = x + eta*g\n",
    "        g = grad_f(x)\n",
    "        n += 1\n",
    "    cv = np.linalg.norm(g) <= eps\n",
    "    return x,n,cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "388f0937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# GENERATING DATA\n",
    "\"\"\"\n",
    "TODO : def a FUNCTION to generate data\n",
    "\"\"\"\n",
    "# 1st test : X in R^2 to visualize results\n",
    "N, d = 50, 2\n",
    "X = np.zeros((N,d))\n",
    "Y = np.zeros(N)\n",
    "for i in range(N):\n",
    "    X[:int(N/2),:] = stat.multivariate_normal([0.5, 0.5], [[1.0, 0.], [0., 0.5]]).rvs(size=int(N/2))\n",
    "    Y[:int(N/2)] = 0\n",
    "    X[int(N/2):,:] = stat.multivariate_normal([2, 2], [[1.0, 0.], [0., 0.5]]).rvs(size=int(N/2))\n",
    "    Y[int(N/2):] = 1\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(6, 6))\n",
    "ax.scatter(X[:int(N/2),0],X[:int(N/2),1],label=fr\"groupe Y=0\", color='red')\n",
    "ax.scatter(X[int(N/2):,0],X[int(N/2):,1],label=fr\"groupe Y=1\", color='blue')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68a777ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Return values of gradient method -----\n",
      "The minimum of loglikelihood is  [ 1.59611726  4.14404259 -6.10709137]\n",
      "Found in  244  iterations\n",
      "Did the method converge ?  True\n"
     ]
    }
   ],
   "source": [
    "# TEST OF THE METHOD\n",
    "x0 = np.array([1., 4., 0.]) # theta = np.array([beta_1,...,beta_d, a])\n",
    "eta = 0.1\n",
    "eps = 0.01\n",
    "Nmax = 500\n",
    "minimum,nb_iter,cv = gradient_met(loglikelihood, x0, eta, eps, Nmax)\n",
    "print(\"----- Return values of gradient method -----\")\n",
    "print(\"The minimum of loglikelihood is \", minimum)\n",
    "print(\"Found in \", nb_iter, \" iterations\")\n",
    "print(\"Did the method converge ? \", cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12833c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTION\n",
    "def predict(x, theta_hat):\n",
    "    \"\"\"\n",
    "    Inputs\n",
    "    ----------\n",
    "    x: observed data\n",
    "    theta_hat: estimator. theta_hat =  [beta_hat_1,...,beta_hat_d, a_hat]\n",
    "    \n",
    "    Outputs\n",
    "    -------\n",
    "    y: group of x prediction\n",
    "    \"\"\"\n",
    "    d = len(theta_hat)\n",
    "    beta_hat = theta_hat[:d-1]\n",
    "    a_hat = theta_hat[d-1]\n",
    "    return int(np.inner(beta_hat,x) + a_hat >= 0) # 1 if true, else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "534e6863",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 314.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of successful predictions over  200  tests :  0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TEST PREDICTION\n",
    "nb_test = 100\n",
    "nb_true = 0\n",
    "\n",
    "# 2*nb_test tests in total : nb_test of y=0 and same for y=1\n",
    "for i in tqdm(range(nb_test)):\n",
    "    # Supposed to be in Y=0\n",
    "    x_test_1 = stat.multivariate_normal([0.5, 0.5], [[1.0, 0.], [0., 0.5]]).rvs()\n",
    "    y_pred_1 = predict(x_test_1,minimum) # theta_hat = minimum cumputed before\n",
    "    if y_pred_1 == 0: nb_true += 1\n",
    "        \n",
    "    # Supposed to be in Y=1\n",
    "    x_test_2 = stat.multivariate_normal([2, 2], [[1.0, 0.], [0., 0.5]]).rvs()\n",
    "    y_pred_2 = predict(x_test_2,minimum) # theta_hat = minimum cumputed before\n",
    "    if y_pred_2 == 1: nb_true += 1\n",
    "\n",
    "print(\"Mean of successful predictions over \",2*nb_test,\" tests : \", nb_true/(2*nb_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27da21d3",
   "metadata": {},
   "source": [
    "## 2.2. Méthode du 2nd ordre : Newton-Raphson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f16315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "153684fb",
   "metadata": {},
   "source": [
    "Voici le code Python implémentant cette méthode :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca82c06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9b3d9a8",
   "metadata": {},
   "source": [
    "## 2.3. Expectation-Maximisation (EM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88bff95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af4a1f55",
   "metadata": {},
   "source": [
    "Voici le code Python implémentant cette méthode :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af5ff70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e50b771",
   "metadata": {},
   "source": [
    "# Références"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab2f4b9",
   "metadata": {},
   "source": [
    "<a href=\"https://en.wikipedia.org/wiki/Logistic_regression\" title=\"WpLR\">Wikipedia - Logistic regression</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4598637",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
