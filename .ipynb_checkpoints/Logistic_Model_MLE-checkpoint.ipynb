{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29e618c5",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92d3091",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dc1f11",
   "metadata": {},
   "source": [
    "## <font color=darkblue>Implémentation du maximum de vraisemblance pour le modèle de régression logistique</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6f705c",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae932025",
   "metadata": {},
   "source": [
    "L'objectif de la régression logistique est d'expliquer une variable binaire par des observations réelles indépendantes. Pour y parvenir on estime le paramètre inconnu qui lie les observations et la variable binaire. On se place donc dans un cadre paramétrique. Commençons par détailler le modèle de régression logistique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b36bcf",
   "metadata": {},
   "source": [
    "# <font color=darkgreen>1. Le modèle</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baaff38",
   "metadata": {},
   "source": [
    "La régression logistique appartient à une classe de modèles dits de classification supervisée. Donnons en une définition formelle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03480928",
   "metadata": {},
   "source": [
    "**Définition** Le `modèle de classification supervisée` correspond à la donnée de $\\mathcal{D}_n = (X_i,Y_i)_{1\\leq i\\leq n}$ les observations où $(X_i,Y_i) \\stackrel{iid}{\\sim} (X,Y)$ un couple générique de loi $P_{X,Y}$ où $X \\in \\mathbb{R}^d$, est la variable dite explicative (de dimension $d \\in \\mathbb{N}$) et $Y \\in \\{ 0,1 \\}$ la variable expliquée."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efae4646",
   "metadata": {},
   "source": [
    "Naturellement, après avoir observé des données ET leurs étiquettes, on aimerait pouvoir faire des prédictions. Sur quelle quantité concentrer nos efforts ? C'est ce qu'on peut espérer sachant la donnée."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f271c2",
   "metadata": {},
   "source": [
    "**Définition** On appelle fonction de régression la fonction\n",
    "$$\n",
    "    \\eta : x \\in \\mathbb{R}^d \\mapsto \\eta(x) = \\mathbb{E}[Y|X=x] = P(Y=1|X=x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020d5b98",
   "metadata": {},
   "source": [
    "Puisque la loi du couple générique $(X,Y)$ est inconnue, nous ferons comme d'habitude en statistique : un estimateur."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a0d4b4",
   "metadata": {},
   "source": [
    "Précisons maintenant le cadre de la régression logistique qui consiste simplement en l'ajout d'une hypothèse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a6283f",
   "metadata": {},
   "source": [
    "**Définition** Le `modèle de régression logistique` correspond à un modèle de classification supervisée sur lequel on fait l'`hypothèse logistique` : $\\exists \\beta \\in \\mathbb{R}^d, \\exists a \\in \\mathbb{R}, \\forall x \\in \\mathbb{R}^d$,\n",
    "$$\n",
    "    log\\left( \\frac{\\eta(x)}{1-\\eta(x)} \\right) = \\beta^Tx+a\n",
    "$$\n",
    "\n",
    "**Il est important de remarquer que** $1 - \\eta(x) = P(Y=0|X=x)$ donc\n",
    "$ P(Y=1|X=x) \\geq P(Y=0|X=x) \\iff log\\left( \\frac{\\eta(x)}{1-\\eta(x)} \\right) \\geq 0 $.\\\n",
    "Par conséquent, \n",
    "$$\\boxed{\\beta^Tx+a \\geq 0 \\implies \\text{Y=1 est plus probable que Y=0}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1d2031",
   "metadata": {},
   "source": [
    "Il nous suffit donc d'estimer les deux paramètres $\\beta$ et $a$. Exprimons donc la vraisemblance du modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e36368",
   "metadata": {},
   "source": [
    "Puisque $\\eta(x) = \\frac{exp(\\beta^Tx+a)}{1+exp\\beta^Tx+a)}$, on a $\\mathcal{L}((Y_i)_{1\\leq i\\leq n} | (X_i)_{1\\leq i\\leq n}) = \\bigotimes_{i=1}^n \\mathcal{B}(\\eta(X_i)) = \\bigotimes_{i=1}^n \\mathcal{B}\\left(\\frac{exp(\\beta^TX_i+a)}{1+exp(\\beta^TX_i+a)}\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500aa888",
   "metadata": {},
   "source": [
    ">**Rappel** : si les $(X_i)_{1\\leq i\\leq n}$ sont indépendants à valeurs dans $(X,\\mathcal{X})$ muni d'une mesure de référence $\\mu$, et que la loi de $X_1$ a une densité $p_{\\theta_0}$ par rapport à $\\mu$ où $p_{\\theta_0} \\in \\left\\{ p_{\\theta}, \\theta \\in \\Theta \\right\\}$, par indépendance des $X_i$, la fonction de `vraisemblance` s'écrit alors\n",
    "$$L_n : \\theta \\mapsto p_{\\theta}(X_1,...,X_n) = \\prod_{i=1}^{n}p_{\\theta}(X_i)\n",
    "$$\n",
    "Et la `log-vraisemblance`\n",
    "$$\n",
    "l_n : \\theta \\mapsto log(p_{\\theta}(X_1,...,X_n)) = \\sum_{i=1}^{n}log(p_{\\theta}(X_i))\n",
    "$$\n",
    "On appelle `maximum de vraisemlance` tout $\\hat{\\theta}_n^{MV}$ tel que\n",
    "$$\n",
    "    \\hat{\\theta}_n^{MV} \\in \\underset{\\theta \\in \\Theta}{\\mathrm{argmin}}\\:l_n(\\theta)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e9bfd5",
   "metadata": {},
   "source": [
    "Puisque la densité d'une $\\mathcal{B}(p)$ peut s'écrire comme $x \\in \\{0,1\\} \\mapsto p^x(1-p)^{1-x}$ et que les données sont indépendantes, la vraisemblance s'écrit\n",
    "$$\n",
    "    \\prod_{i=1}^n\n",
    "    \\left(     \\frac{exp(\\beta^TX_i+a)}{1+exp(\\beta^TX_i+a)} \\right)^{X_i}\n",
    "    \\left( 1 - \\frac{exp(\\beta^TX_i+a)}{1+exp(\\beta^TX_i+a)} \\right)^{1 - X_i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca49f5f6",
   "metadata": {},
   "source": [
    "Finalement on obtient la log-vraisemblance du modèle logistique\n",
    "<font color=darkred>\n",
    "    $$l_n(\\beta,a) = \\sum_{i=1}^n \\left( X_i\\left(\\beta^TX_i+a\\right) - log\\left(1+e^{\\beta^TX_i+a}\\right) \\right)$$\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd99609",
   "metadata": {},
   "source": [
    "Une fois qu'on a estimé $\\beta$ et $a$ par $\\hat{\\beta}$ et $\\hat{a}$ en maximisant cette vraisemblance, on obtient l'estimateur plug-in du classifieur $h(x) = \\mathbb{1}\\left\\{ \\eta(x) \\geq \\frac{1}{2} \\right\\}$ :\n",
    "<font color=darkred>\n",
    "    $$\\hat{h}(x) = \\mathbb{1}\\left\\{ \\hat{\\beta}^Tx + \\hat{a} \\geq 0 \\right\\}$$\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b62177",
   "metadata": {},
   "source": [
    "**La question est maintenant de savoir comment maximiser cette vraisemblance**. En effet la tâche n'est pas simple car son maximum n'est pas explicitement calculable. Ainsi l'objectif de ce notebook est de voir quelles méthodes nous permettent de contourner ce problème. Nous commençerons par la célèbre méthode de gradient, puis nous passerons à une méthode du 2nd ordre : Newton-Raphson. Finalement nous expliquerons l'algorithme Expectation-Maximisation introduit en 1977 et plus tard largement utilisé en apprentissage automatique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beffc40d",
   "metadata": {},
   "source": [
    "# <font color=darkgreen>2. Maximisation de la vraisemblance</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5259160",
   "metadata": {},
   "source": [
    "## 2.1. Méthode du 1er ordre : montée de gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c73dc6a",
   "metadata": {},
   "source": [
    "Cette méthode par de l'idée intuitive que pour atteindre le maximum il faut monter, or c'est le gradient qui nous indique la route à prendre pour monter le plus. En considérant que $\\theta = (\\beta, a)$ est le paramètre recherché, on produit une suite $\\left\\{ \\hat{\\theta}^{(K)} \\right\\}_{K\\geq0}$ d'estimateurs de $\\theta$. L'algorithme est le suivant :\\\n",
    "`Initialisation :` $\\hat{\\theta}^{(0)}$ est choisi arbitrairement\\\n",
    "`Itérations :` $\\forall K \\geq 0, \\hat{\\theta}^{(K+1)} = \\hat{\\theta}^{(K)} + \\eta_{K+1}\\nabla_{\\theta}l_n\\left(\\hat{\\theta}^{(K)}\\right)$\\\n",
    "où les $\\left(\\eta_K\\right)_{K\\geq1}$ sont des pas dans $\\mathbb{R}_+^*$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273c5998",
   "metadata": {},
   "source": [
    "Plusieurs critères d'arrêts sont possibles et peuvent être combiner. On peut par exemple citer :\n",
    "- lorsque le gradient de f est suffisamment petit : $\\| \\nabla_{\\theta}l_n\\left(\\hat{\\theta}^{(K)}\\right) \\| \\leq \\varepsilon$\n",
    "- lorsque les itérés ne progressent plus suffisamment : $\\|\\hat{\\theta}^{(K+1)} - \\hat{\\theta}^{(K)}\\| \\leq \\varepsilon$\n",
    "- lorsque les valeurs de f ne changent plus suffisamment : $\\|l_n\\left(\\hat{\\theta}^{(K+1)}\\right) - l_n\\left(\\hat{\\theta}^{(K)}\\right)\\| \\leq \\varepsilon$\n",
    "\n",
    "En plus de ces critères on peut ajouter une condition sur un nombre d'itérations maximum à ne pas dépasser."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd2a555",
   "metadata": {},
   "source": [
    "Code Python implémentant cette méthode :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62f7fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loglikelihood(beta,a,X):\n",
    "    \"\"\"\n",
    "    Inputs\n",
    "    ----------\n",
    "    beta: one of the 2 parameters of logistic regression\n",
    "    a: one of the 2 parameters of logistic regression\n",
    "    X: data (global variable ?)\n",
    "    \n",
    "    Outputs\n",
    "    -------\n",
    "    logl: loglikelihood\n",
    "    \"\"\"\n",
    "    # Vectorization\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27da21d3",
   "metadata": {},
   "source": [
    "## 2.2. Méthode du 2nd ordre : Newton-Raphson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f16315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "153684fb",
   "metadata": {},
   "source": [
    "Code Python implémentant cette méthode :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca82c06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9b3d9a8",
   "metadata": {},
   "source": [
    "## 2.3. Expectation-Maximisation (EM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88bff95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af4a1f55",
   "metadata": {},
   "source": [
    "Code Python implémentant cette méthode :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af5ff70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e50b771",
   "metadata": {},
   "source": [
    "# Références"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab2f4b9",
   "metadata": {},
   "source": [
    "<a href=\"https://en.wikipedia.org/wiki/Logistic_regression\" title=\"WpLR\">Wikipedia - Logistic regression</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4598637",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
